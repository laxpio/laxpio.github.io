## 序章
一直以来总想把个人的学习内容记录下来，在这过程中总会有各种理由导致该计划没有实现；借这次外界环境的变更，再次开始记录日记，希望能持续坚持下来；
记录的内容只是属于个人在记录时了解的信息，存在错误、混淆的内容是在所难免，当然在个人意识到错误时，亦会进行更新（错误的内容亦会保留）
##  第 0 章 初涉LLMs
#### 大语言模型来了
-  出生
大语言模型（Large Language Models, LLMs）是自然语言处理（NLP）领域的重要发展，它能够理解和生成人类语言；在发展的时间上，可以追溯到20 世纪 50 年代；
- 历程
**20 世纪 50 年代**，人们开始进行神经网络和神经信息处理系统的实验，尝试让计算机处理自然语言；
**20 世纪 60 年代**，世界上第一个聊天机器人 Eliza 诞生，使用模式识别来模拟人类对话，将用户的输入转化为问题，并根据一组预定义的规则生成响应；
**20 世纪末 - 21 世纪初**，算力不断提升，互联网兴起，数据爆发式积累，进而出现一些新的技术和模型，如1997年的长短期记忆（LSTM）网络；
**21 世纪初 - 2017 年**，深度学习快速发展，2013 年，自然语言处理模型 Word2Vec 诞生（将单词转换为向量的 “词向量模型”），2017 年，Vaswani 等人提出了 Transformer 架构（具有独特的注意力机制，为大语言模型的发展提供了重要的技术支持）；
**2018 年 - 2021 年**，基础模型提出，2018 年，Google 和 OpenAI 分别提出了 BERT-1 和 GPT-1 模型，开启了预训练语言模型时代；
**2019 年 - 2022 年**，研究人员开始探索在不针对单一任务进行微调的情况下如何能够发挥大规模语言模型的能力，同时提出指令微调方案（2022 年，Ouyang 等人提出了使用 “有监督微调 + 强化学习” 的 InstructGPT 算法，有效提升了模型的性能）；
**2022 年至今**，爆发式发展，遍地开花；从 2022 年开始，大模型呈现爆发式的增长，各大公司和研究机构相继发布了此类系统；同时模型的参数规模不停的扩大；
- 狼来了
大语言模型对于社会发展带来一定的冲击，个人认为目前还无法完全评估其冲击的范围；乐观来看，提升了工作的效率，降低了知识学习获取的门槛，也对科研有一定的促进作用；但悲观来说，社会将带来一定的动荡（岗位取代带来的失业问题），伦理道德，隐私数据安全，知识产权等都将收到挑战；有兴趣的可以自行了解下 ***DAN聊天机器人***；
#### 国外的一些大模型
##### OpenAI GPT
https://openai.com/
```
基于深度学习技术的自然语言处理模型。它基于Transformer架构，通过大量文本数据进行预训练，能够理解和生成类似人类的文本。
历程：
GPT-1，GPT-2，GPT-3，GPT-3.5,GPT-4,GPT-4o
使用方式：
a.) 进入官网ChatGPT页面，直接进行交互；
b.) 通过OpenAI提供的开放API接口调用
c.) 使用第三方提供的服务（封装了OpenAI的API接口）
```

##### Meta LLaMA
https://llama.meta.com
```
LLaMA 也是建立在 Transformer 基础架构上的自回归语言模型，采用了先进的神经网络架构和生成对抗网络（GAN）技术，展现出在自然语言处理（NLP）和文本生成方面的卓越性能。模型还具备多模态AI能力，能够处理图像和文本等多种数据形式。
历程:
Llama 1,Llama 2,Llama 3,Llama 3.1
使用方式：
a.) 使用Meta官方提供的开放API接口；
b.) 通过第三方平台使用（如Hugging Face）；
c.) 自建环境，下载 LLaMA 的模型文件并运行该模型；
```
其他相关链接：
LLaMA2 - 开源（https://github.com/facebookresearch/llama）
LLaMA3 - 开源（https://github.com/meta-llama/llama3）

##### xAI Grok
https://github.com/xai-org/grok-1
```
Grok模型虽然具体的技术细节可能没有完全公开，但可以推测 Grok 使用了类似于其他大型语言模型的技术基础，结合了深度学习和大规模数据训练,其以先进的推理能力而闻名，旨在理解和生成自然语言，同时处理包括文本、图像和声音在内的多模态输入。
历程：
Grok-1,Grok-1.5V,Grok-2,Grok-2 mini
使用方式：
a.) 订阅 X 平台的 Premium 或 Premium + 服务,即可在X平台上与 Grok 进行交互，输入问题并获取回答;
b.) 自建环境，下载Grok的模型文件并运行该模型；
```
其他相关链接：
Grok-1 - 开源（https://github.com/xai-org/grok-1)

##### Google Gemini 
https://gemini.google.com
```
Google 的下一代 AI 项目，旨在处理各种复杂的任务，从文本理解到图像和视频分析，再到编程和数学问题解决;
历程：
Gemini 1.0, Gemini 1.5, Gemini 1.5 Pro, Gemini 1.5 Flash
使用方式：
a.) 访问 Google Bard 网站(https://bard.google.com/)
b.) 使用Google官方提供的开放API接口；
c.) 在 Google Workspace 中使用(订阅 Google One AI Premium 计划)
```

##### Mistral AI  Codestral
https://docs.mistral.ai/capabilities/code_generation/
```
大型编程语言模型，Mistral AI 开发，是一个专门用于代码生成的 22B 参数模型，支持 80 多种编程语言，专为提高软件开发效率而设计；Codestral 采用了 “非生产”（non-production）许可协议，仅限于研究用途，不得用于商业目的。
使用方式：
a.) 通过访问Mistral AI 的在线聊天界面(https://chat.mistral.ai/chat)来使用;
b.) 在开发环境中使用(安装 Continue.dev 或 TabNine 等插件,选择 Codestral 作为代码补全或交互的模型)
c.) 通过第三方平台使用（如Hugging Face）
```
其他相关链接：
https://chat.mistral.ai/chat/
Codestral - 开源（https://huggingface.co/mistralai/Codestral-22B-v0.1）

#### 国内的一些大模型
##### Kimi
https://kimi.moonshot.cn/chat/crfb394ubmsandu0ibs0
```
月之暗面（moonshotai）公司研发推出的一款人工智能助手产品；
使用方式：
a.)  使用Kimi 的官方网站（https://kimi.moonshot.cn/chat）
b.)  使用微信小程序 “Kimi智能助手”
c.) 浏览器安装Kimi 的插件
```

##### 豆包大模型
https://www.doubao.com/chat
```
是由字节跳动公司自研的人工智能大模型，提供的是一个有多模态能力的模型家族；
发展历程：
云雀， 豆包
使用方式：
a.) 使用官方网站(https://www.doubao.com/chat)
b.) 通过字节跳动的开发者平台使用API（火山引擎）
c.) 使用扣子平台，构建Bot
```
其他关联信息：
火山引擎 （https://www.volcengine.com/）
火山方舟（https://www.volcengine.com/product/ark）
扣子平台（https://www.volcengine.com/product/coze-pro）
https://www.volcengine.com/product/doubao

##### 腾讯混元大模型
https://hunyuan.tencent.com/
```
由腾讯研发的大语言模型，具有强大的中文处理能力、逻辑推理能力以及任务执行能力。
使用方式：
a.) 使用官方网站 (https://yuanbao.tencent.com/chat)
b.) 通过腾讯的开发者平台使用API
c.) 使用微信小程序“腾讯混元助手”
d.) 自建环境，下载混元大模型并运行该模型（https://github.com/Tencent/HunyuanDiT）；
e.) 通过腾讯元器构建应用(https://yuanqi.tencent.com/agent-shop)
```
其他关联信息：
混元大模型 - 开源 （https://github.com/Tencent/HunyuanDiT）
腾讯元器（https://yuanqi.tencent.com/agent-shop）
https://cloud.tencent.com/product/hunyuan

##### 讯飞火星大模型
https://xinghuo.xfyun.cn/
```
由科大讯飞推出的一款新一代认知智能大模型，具备跨领域的知识和语言理解能力，能够基于自然对话方式理解与执行任务。
使用方式：
a.)  使用官方网站(https://xinghuo.xfyun.cn/)
b.) 通过官方的开发者平台使用API
c.) 通过App使用，“讯飞星火” APP
d.) 自建环境，下载火星大模型并运行该模型(https://gitee.com/iflytekopensource)
```
其他关联信息：
https://xinghuo.xfyun.cn/openSource
火星大模型 - 开源 （https://gitee.com/iflytekopensource）
https://xinghuo.xfyun.cn/desk

##### 阿里通义大模型
https://qianwen.aliyun.com/
```
阿里巴巴集团推出的一款人工智能语言模型，它基于深度学习和自然语言处理技术，具备强大的语义理解和生成能力。
使用方式：
a.) 使用官方网站 (https://qianwen.aliyun.com/)
b.) 通过App使用，“通义” APP
c.) 通过官方的平台使用API(https://dashscope.console.aliyun.com)
d.) 自建环境，下载Qwen大模型并运行该模型（https://github.com/QwenLM）
```
其他关联信息：
平台百炼 （https://www.aliyun.com/product/bailian）
Qwen2 - 开源 （https://github.com/QwenLM）
https://help.aliyun.com/zh/model-studio/developer-reference/what-is-qwen-llm?spm=a2c4g.11186623.0.i3

##### 百度文心大模型
https://wenxin.baidu.com/
```
百度自主研发的产业级知识增强大模型，形成了基础-任务-行业三级大模型体系，包括自然语言处理、视觉、跨模态等基础大模型，对话、跨语言、搜索、信息抽取等任务大模型，生物计算领域大模型，行业大模型，以及支撑大模型应用的工具平台
使用方式：
a.) 访问文心大模型的官网(https://yiyan.baidu.com/)
b.) 通过官方的平台使用API(https://qianfan.cloud.baidu.com/)
c.) 通过App使用，文心一言APP
```
其他关联信息：
千帆大模型平台 （https://qianfan.cloud.baidu.com/）

##### DeepSeek
https://www.deepseek.com/zh
```
DeepSeek AI 开发的 2360 亿参数模型，专注于高效、经济、易用的混合专家（MoE）语言模型
历程：
DeepSeek 67b，DeepSeek-V2，DeepSeek-V2.5
使用方式：
a.) 访问DeepSeek大模型的官网(https://platform.deepseek.com/)
b.) 通过官方的平台使用API(https://platform.deepseek.com/api-docs/zh-cn/)
c.) 自建环境，下载DeepSeek-V2大模型并运行该模型（https://github.com/deepseek-ai/DeepSeek-V2）
```
其他关联信息：
DeepSeek-V2 - 开源（https://github.com/deepseek-ai/DeepSeek-V2）

##### 智谱AI  智谱清言
https://www.zhipuai.cn/
```
智谱 AI 的 GLM 是一系列具有强大性能和广泛应用的人工智能语言模型，具有 90 亿参数，支持多种语言和多模态输入。
历程：
GLM-10B, GLM-130B, ChatGLM-6B, GLM-4
使用方式：
a.) 使用官方网站 (https://chatglm.cn/?lang=zh)
b.) 通过App使用，“智谱清言” APP
c.) 使用微信小程序“智谱清言”
d.) 通过官方的平台使用API(https://bigmodel.cn/)
e.) 自建环境，下载GLM大模型并运行该模型（https://github.com/THUDM/GLM-4）
```
其他关联信息：
GLM-4 - 开源（https://github.com/THUDM/GLM-4）
ChatGLM-6B - 开源 （https://github.com/THUDM/ChatGLM-6B）

##### 其他大模型
***华为 盘古大模型*** （华为云企业账号才可申请体验权限）
***商汤 日日新大模型***
***网易 商和大模型***
***百川智能 百川大模型***
***零一万物科技 零一万物大模型***
***稀宇科技 MiniMax大模型***
***IDEA 研究院 姜子牙大模型***（从 Llama 的基础上进行改进和训练）
***BELLE大模型***（基于斯坦福的 Alpaca 模型进行了中文优化和代码修改）
***元语智能 元语大模型***

#### 说在最后
初步了解LLMs时，就是借用了相关的大模型应用的对话服务和搜索能力，不同应用对于同一个问题的答复确实也存在比较大的差异（其中好坏的判断有较强的主观性，就不在公开日记中体现），奈何本人英语较差，无法做更全面的体验；
